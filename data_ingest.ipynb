{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pylab import rcParams\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.metrics import make_scorer,mean_absolute_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(pth):\n",
    "    df = pd.read_csv(pth,index_col='Date',parse_dates=True,na_values=['nan']).drop(['ID'],axis=1)\n",
    "    df = df.fillna(method='ffill',axis=1)\n",
    "    df = df.fillna(method='bfill',axis=1)\n",
    "    #df.info()\n",
    "    #df.describe().T\n",
    "    return df\n",
    "\n",
    "def gen_time_graph(df,stid):\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.subplot(6, 1, 1)\n",
    "    sns.scatterplot(data=df, x=df.index, y='AQI',hue='AQI',size=3\n",
    "    ).get_legend().remove()\n",
    "    plt.ylabel('AQI')\n",
    "    plt.margins(x=0)\n",
    "    plt.xlabel(xlabel=None)\n",
    "\n",
    "    plt.subplot(6, 1, 2)\n",
    "    sns.scatterplot(data=df, x=df.index, y='PM2.5',hue='AQI',size=3).get_legend().remove()\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.margins(x=0)\n",
    "    plt.xlabel(xlabel=None)\n",
    "\n",
    "    plt.subplot(6, 1, 3)\n",
    "    sns.scatterplot(data=df, x=df.index, y='PM10',hue='AQI',size=3).get_legend().remove()\n",
    "    plt.ylabel('PM10')\n",
    "    plt.margins(x=0)\n",
    "    plt.xlabel(xlabel=None)\n",
    "\n",
    "    plt.subplot(6, 1, 4)\n",
    "    sns.scatterplot(data=df, x=df.index, y='O3',hue='AQI',size=6).get_legend().remove()\n",
    "    plt.ylabel('O3')\n",
    "    plt.margins(x=0)\n",
    "    plt.xlabel(xlabel=None)\n",
    "\n",
    "    plt.subplot(6, 1, 5)\n",
    "    sns.scatterplot(data=df, x=df.index, y='CO',hue='AQI',size=3).get_legend().remove()\n",
    "    plt.ylabel('CO')\n",
    "    plt.margins(x=0)\n",
    "    plt.xlabel(xlabel=None)\n",
    "\n",
    "    plt.subplot(6, 1, 6)\n",
    "    sns.scatterplot(data=df, x=df.index, y='SO2',hue='AQI',size=3).get_legend().remove()\n",
    "    plt.ylabel('SO2')\n",
    "    plt.margins(x=0)\n",
    "    plt.xlabel(xlabel=None)\n",
    "\n",
    "    # Set plot title\n",
    "    plt.suptitle('Pollutants Over Time')\n",
    "\n",
    "    # Adjust space between subplots\n",
    "    plt.subplots_adjust(hspace=0.8)\n",
    "    plt.margins(x=0)\n",
    "\n",
    "    plt.savefig(f'./media/{stid}_Pollutans_Over_Time.jpg')\n",
    "    plt.clf()\n",
    "\n",
    "def get_heatmap(df,stid):\n",
    "    corr_matrix = df[['PM2.5', 'PM10', 'O3', 'CO', 'SO2', 'AQI']].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.savefig(f'./media/{stid}_heatmap.jpg')\n",
    "\n",
    "def get_freq_dist(df,stid):\n",
    "    fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15,5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(df.columns):\n",
    "        ax = axes[i]\n",
    "        ax.hist(df[col])\n",
    "        ax.set_title(col)\n",
    "\n",
    "    plt.suptitle('Frequency Distribution of Pollutants')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./media/{stid}_freq_dist.jpg')\n",
    "\n",
    "def get_monthly_trend(df, stid):\n",
    "    monthly_means = df.groupby([df.index.year, df.index.month]).mean()\n",
    "    monthly_means.index.rename(('year','month'),inplace=True)\n",
    "    #monthly_means.head(10)\n",
    "    yrs = list(monthly_means.index.get_level_values(0).unique().sort_values())\n",
    "    fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15,5))\n",
    "    axes = axes.flatten()\n",
    "    for i, col in enumerate(monthly_means.columns):\n",
    "        ax = axes[i]\n",
    "        width = 0\n",
    "        for yr in yrs:\n",
    "            x1 = monthly_means.loc[[yr]].index.get_level_values(1).unique().sort_values()\n",
    "            y1 = monthly_means.loc[[yr]][col]\n",
    "            ax.bar(x1 + width, y1,width = 0.25,label=yr)\n",
    "            width += 0.25        \n",
    "            ax.legend()\n",
    "            ax.set_title(col)\n",
    "        ax.set_xticks([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "        ax.set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'],fontsize=9)\n",
    "\n",
    "    plt.suptitle('Monthly Comparison of Average Value of Pollutants')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./media/{stid}_monthy_trend.jpg')\n",
    "\n",
    "def get_stationarity(df):\n",
    "    res = ''\n",
    "    for col in ['PM2.5', 'PM10', 'O3', 'CO', 'SO2']:\n",
    "        adf_result = adfuller(df[col])\n",
    "        if adf_result[1] > 0.05:\n",
    "            res += f'{col}: time series is not stationary.\\n'\n",
    "        else:\n",
    "            res += f'{col}: time series is stationary.\\n'\n",
    "    return res\n",
    "\n",
    "def get_acf(df,stid):\n",
    "    for col in ['PM2.5', 'PM10', 'O3', 'CO', 'SO2']:\n",
    "        plot_acf(df[col],lags=50)\n",
    "        plt.savefig(f'./media/{stid}_{col}_autocorelation.jpg')\n",
    "\n",
    "def get_decomposition(df,stid):\n",
    "    for col in ['PM2.5', 'PM10', 'O3', 'CO', 'SO2']:\n",
    "        rcParams['figure.figsize'] = 15, 8\n",
    "        decomposition = seasonal_decompose(df[col], model='additive',period=30)\n",
    "        decomposition.plot()\n",
    "        plt.savefig(f'./media/{stid}_{col}_decomposition.jpg')\n",
    "\n",
    "def forecasting(df,daterange,stid):\n",
    "    df_pol = pd.DataFrame({'ds': daterange}) \n",
    "    for col in ['PM2.5', 'PM10', 'O3', 'CO', 'SO2']:\n",
    "        df_tmp = pd.DataFrame({'ds': df[col].index, 'y': df[col]})\n",
    "        #df_tmp.tail()\n",
    "        m = Prophet(changepoint_prior_scale= 0.5, seasonality_prior_scale= 0.01,)\n",
    "        m.fit(df_tmp)\n",
    "        future = pd.DataFrame({'ds':daterange})\n",
    "        forecast = m.predict(future)\n",
    "        forecast = forecast[['ds','yhat']].rename(columns={'yhat': col})\n",
    "        df_pol = pd.merge(df_pol,forecast,on='ds',how='left')\n",
    "    return df_pol\n",
    "\n",
    "def hp_tune(df):\n",
    "    param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "    # Generate all combinations of parameters\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "    # Use cross validation to evaluate all parameters\n",
    "    for params in all_params:\n",
    "        m = Prophet(**params).fit(df)  # Fit model with given params\n",
    "        df_cv = cross_validation(m, horizon='28 days')\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['mae'].values[0])\n",
    "\n",
    "    # Find the best parameters\n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['mae'] = rmses\n",
    "    \n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    return best_params\n",
    "\n",
    "def error_metric(y_pred,y_true):\n",
    "    errors = np.abs(y_pred - y_true)\n",
    "    mask = y_true > y_pred\n",
    "    errors[mask] *= 1.5\n",
    "    return np.mean(errors)\n",
    "\n",
    "def LGBM_MMAE(y_pred,y_true):\n",
    "    errors = np.abs(y_pred - y_true)\n",
    "    mask = y_true > y_pred\n",
    "    errors[mask] *= 1.5\n",
    "    return ('MMAE', np.mean(errors), False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_grph = False\n",
    "clf = 'lgbm'\n",
    "files = glob.glob('./processed' + \"/*.csv\")\n",
    "\n",
    "for filepath in files:\n",
    "    filename = os.path.basename(filepath)\n",
    "    Station_id = filename[:filename.rindex('.')]\n",
    "    data = read_data(filepath)\n",
    "    shape = data.shape\n",
    "    row_split_no = int(np.floor(shape[0]*0.7))\n",
    "    print(f'Processing {Station_id} : \\n\\n')\n",
    "    \n",
    "\n",
    "    start_date = data.index.max() + pd.Timedelta(days=1)\n",
    "    end_date = start_date + pd.Timedelta(days=27)\n",
    "    date_range = pd.date_range(start_date,end_date)\n",
    "\n",
    "    if gen_grph:\n",
    "        gen_time_graph(data,Station_id)\n",
    "        get_heatmap(data,Station_id)\n",
    "        get_freq_dist(data,Station_id)\n",
    "        get_monthly_trend(data,Station_id)\n",
    "\n",
    "    if gen_grph:\n",
    "        result = get_stationarity(data)\n",
    "        print(f'{Station_id}: \\n\\n {result}')\n",
    "\n",
    "    if gen_grph:\n",
    "        get_acf(data,Station_id)\n",
    "        get_decomposition(data,Station_id)\n",
    "\n",
    "    pol_pred = forecasting(data,date_range,Station_id).set_index('ds')\n",
    "\n",
    "    X = data[['PM2.5', 'PM10', 'O3', 'CO', 'SO2']]\n",
    "    Y = data['AQI']\n",
    "    X_train = data.iloc[0:row_split_no][['PM2.5', 'PM10', 'O3', 'CO', 'SO2']]\n",
    "    Y_train = data.iloc[0:row_split_no]['AQI']\n",
    "    X_test =  data.iloc[row_split_no:][['PM2.5', 'PM10', 'O3', 'CO', 'SO2']]\n",
    "    Y_test = data.iloc[row_split_no:]['AQI']\n",
    "\n",
    "    if clf == 'lgbm':\n",
    "        model = lgbm.LGBMRegressor(num_leaves=9,n_estimators=48)\n",
    "        model.fit(X_train,Y_train,eval_metric=LGBM_MMAE)\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "        error = mean_absolute_error(Y_test,Y_pred)\n",
    "        print(f'LGBM test MAE : {error}')\n",
    "\n",
    "        Y_pred_train = model.predict(X_train)\n",
    "        error = mean_absolute_error(Y_pred_train,Y_train)\n",
    "        print(f'LGBM train MAE : {error} \\n')\n",
    "\n",
    "        Y_test_forecast = model.predict(pol_pred)\n",
    "        temp = pd.DataFrame({'Station_ID':Station_id + '_' + date_range.astype(str)})\n",
    "        z = temp['Station_ID'].values\n",
    "        predictions = np.transpose(np.vstack((z,Y_test_forecast)))\n",
    "\n",
    "        final  = pd.DataFrame(data=predictions,columns = ['ID_Date','AQI'])\n",
    "        final.to_csv('submission.csv',mode='a',index=False, header=False)\n",
    "\n",
    "    if clf == 'ada':\n",
    "        params = {'n_estimators':[1,20,30,40,50,80,100,120,150,200],'learning_rate':[0.01,0.1,1,1.5,2.0,5.0]}\n",
    "        model = AdaBoostRegressor()\n",
    "        grid_search = GridSearchCV(estimator=model,param_grid=params,scoring=make_scorer(error_metric,greater_is_better=False),cv=10)\n",
    "        grid_search.fit(X,Y)\n",
    "        print(f'\\n Best params : {grid_search.best_params_}\\n\\n Best Score : {grid_search.best_score_}')\n",
    "\n",
    "        best = grid_search.best_estimator_\n",
    "        Y_test_forecast = best.predict(pol_pred)\n",
    "        temp = pd.DataFrame({'Station_ID':Station_id + '_' + date_range.astype(str)})\n",
    "        z = temp['Station_ID'].values\n",
    "        predictions = np.transpose(np.vstack((z,Y_test_forecast)))\n",
    "\n",
    "        final  = pd.DataFrame(data=predictions,columns = ['ID_Date','AQI'])\n",
    "        final.to_csv('submission.csv',mode='a',index=False, header=False)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h2o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
